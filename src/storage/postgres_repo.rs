use sqlx::{Pool, Postgres, PgPool, Row};
use anyhow::{Result, Context};
use tracing::{info, error, debug};
use chrono::{DateTime, Utc};
use uuid::Uuid;
use std::time::Duration;

use crate::models::{AggregatedMetric, MetricFilter, MetricStats};
use crate::config::DatabaseConfig;

/// PostgreSQLå­˜å‚¨ä»“åº“
/// 
/// è´Ÿè´£ä¸PostgreSQLæ•°æ®åº“çš„æ‰€æœ‰äº¤äº’æ“ä½œ
/// åŒ…æ‹¬æ•°æ®çš„å¢åˆ æ”¹æŸ¥å’Œç»Ÿè®¡åˆ†æ
pub struct PostgresRepository {
    /// æ•°æ®åº“è¿æ¥æ± 
    pool: PgPool,
}

impl PostgresRepository {
    /// åˆ›å»ºæ–°çš„PostgreSQLå­˜å‚¨ä»“åº“
    /// 
    /// # å‚æ•°
    /// * `config` - æ•°æ®åº“é…ç½®
    /// 
    /// # è¿”å›
    /// * `Result<Self>` - åˆ›å»ºçš„å­˜å‚¨ä»“åº“æˆ–é”™è¯¯
    pub async fn new(config: &DatabaseConfig) -> Result<Self> {
        info!("ğŸ”— æ­£åœ¨è¿æ¥åˆ°PostgreSQLæ•°æ®åº“...");
        
        // åˆ›å»ºæ•°æ®åº“è¿æ¥æ± 
        let pool = sqlx::postgres::PgPoolOptions::new()
            .max_connections(config.max_connections)
            .acquire_timeout(Duration::from_secs(config.timeout_seconds))
            .connect(&config.url)
            .await
            .context("åˆ›å»ºæ•°æ®åº“è¿æ¥æ± å¤±è´¥")?;
        
        let repo = Self { pool };
        
        // åˆå§‹åŒ–æ•°æ®åº“è¡¨
        repo.init_tables().await?;
        
        info!("âœ… PostgreSQLæ•°æ®åº“è¿æ¥æˆåŠŸ");
        
        Ok(repo)
    }
    
    /// åˆå§‹åŒ–æ•°æ®åº“è¡¨
    /// 
    /// åˆ›å»ºå¿…è¦çš„è¡¨ç»“æ„å’Œç´¢å¼•
    async fn init_tables(&self) -> Result<()> {
        info!("ğŸ“‹ æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“è¡¨...");
        
        // åˆ›å»ºèšåˆæŒ‡æ ‡è¡¨
        sqlx::query(r#"
            CREATE TABLE IF NOT EXISTS aggregated_metrics (
                id UUID PRIMARY KEY,
                source VARCHAR(50) NOT NULL,
                metric_name VARCHAR(100) NOT NULL,
                value JSONB NOT NULL,
                timestamp TIMESTAMPTZ NOT NULL,
                created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
                updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
                metadata JSONB
            )
        "#)
        .execute(&self.pool)
        .await
        .context("åˆ›å»ºaggregated_metricsè¡¨å¤±è´¥")?;
        
        // åˆ›å»ºç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
        sqlx::query("CREATE INDEX IF NOT EXISTS idx_metrics_source ON aggregated_metrics(source)")
            .execute(&self.pool)
            .await
            .context("åˆ›å»ºsourceç´¢å¼•å¤±è´¥")?;
        
        sqlx::query("CREATE INDEX IF NOT EXISTS idx_metrics_metric_name ON aggregated_metrics(metric_name)")
            .execute(&self.pool)
            .await
            .context("åˆ›å»ºmetric_nameç´¢å¼•å¤±è´¥")?;
        
        sqlx::query("CREATE INDEX IF NOT EXISTS idx_metrics_timestamp ON aggregated_metrics(timestamp)")
            .execute(&self.pool)
            .await
            .context("åˆ›å»ºtimestampç´¢å¼•å¤±è´¥")?;
        
        sqlx::query("CREATE INDEX IF NOT EXISTS idx_metrics_source_metric ON aggregated_metrics(source, metric_name)")
            .execute(&self.pool)
            .await
            .context("åˆ›å»ºå¤åˆç´¢å¼•å¤±è´¥")?;
        
        info!("âœ… æ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ");
        
        Ok(())
    }
    
    /// ä¿å­˜èšåˆæŒ‡æ ‡
    /// 
    /// # å‚æ•°
    /// * `metrics` - è¦ä¿å­˜çš„æŒ‡æ ‡åˆ—è¡¨
    /// 
    /// # è¿”å›
    /// * `Result<usize>` - ä¿å­˜çš„è®°å½•æ•°æˆ–é”™è¯¯
    pub async fn save_metrics(&self, metrics: &[AggregatedMetric]) -> Result<usize> {
        if metrics.is_empty() {
            return Ok(0);
        }
        
        debug!("ğŸ’¾ æ­£åœ¨ä¿å­˜ {} æ¡æŒ‡æ ‡æ•°æ®", metrics.len());
        
        let mut tx = self.pool.begin().await.context("å¼€å§‹äº‹åŠ¡å¤±è´¥")?;
        
        let mut saved_count = 0;
        
        for metric in metrics {
            let result = sqlx::query(r#"
                INSERT INTO aggregated_metrics (
                    id, source, metric_name, value, timestamp, created_at, updated_at, metadata
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                ON CONFLICT (id) DO UPDATE SET
                    value = EXCLUDED.value,
                    updated_at = EXCLUDED.updated_at,
                    metadata = EXCLUDED.metadata
            "#)
            .bind(&metric.id)
            .bind(&metric.source)
            .bind(&metric.metric_name)
            .bind(&metric.value)
            .bind(&metric.timestamp)
            .bind(&metric.created_at)
            .bind(&metric.updated_at)
            .bind(&metric.metadata)
            .execute(&mut *tx)
            .await;
            
            match result {
                Ok(_) => saved_count += 1,
                Err(e) => {
                    error!("âŒ ä¿å­˜æŒ‡æ ‡å¤±è´¥: {}", e);
                    // ç»§ç»­å¤„ç†å…¶ä»–æŒ‡æ ‡ï¼Œä¸ä¸­æ–­æ•´ä¸ªæ‰¹æ¬¡
                }
            }
        }
        
        tx.commit().await.context("æäº¤äº‹åŠ¡å¤±è´¥")?;
        
        info!("âœ… æˆåŠŸä¿å­˜ {} æ¡æŒ‡æ ‡æ•°æ®", saved_count);
        
        Ok(saved_count)
    }
    
    /// æ ¹æ®è¿‡æ»¤æ¡ä»¶æŸ¥è¯¢æŒ‡æ ‡
    /// 
    /// # å‚æ•°
    /// * `filter` - æŸ¥è¯¢è¿‡æ»¤æ¡ä»¶
    /// 
    /// # è¿”å›
    /// * `Result<Vec<AggregatedMetric>>` - æŸ¥è¯¢ç»“æœæˆ–é”™è¯¯
    pub async fn get_metrics(&self, filter: &MetricFilter) -> Result<Vec<AggregatedMetric>> {
        let mut query = String::from("SELECT * FROM aggregated_metrics WHERE 1=1");
        let mut params: Vec<&(dyn sqlx::Encode<Postgres> + Send + Sync)> = Vec::new();
        let mut param_count = 0;
        
        // æ„å»ºåŠ¨æ€æŸ¥è¯¢æ¡ä»¶
        if let Some(source) = &filter.source {
            param_count += 1;
            query.push_str(&format!(" AND source = ${}", param_count));
            params.push(source);
        }
        
        if let Some(metric_name) = &filter.metric_name {
            param_count += 1;
            query.push_str(&format!(" AND metric_name = ${}", param_count));
            params.push(metric_name);
        }
        
        if let Some(time_range) = &filter.time_range {
            param_count += 1;
            query.push_str(&format!(" AND timestamp >= ${}", param_count));
            params.push(&time_range.start);
            
            param_count += 1;
            query.push_str(&format!(" AND timestamp <= ${}", param_count));
            params.push(&time_range.end);
        }
        
        // æ·»åŠ æ’åº
        query.push_str(" ORDER BY timestamp DESC");
        
        // æ·»åŠ é™åˆ¶å’Œåç§»
        if let Some(limit) = filter.limit {
            param_count += 1;
            query.push_str(&format!(" LIMIT ${}", param_count));
            params.push(&limit);
        }
        
        if let Some(offset) = filter.offset {
            param_count += 1;
            query.push_str(&format!(" OFFSET ${}", param_count));
            params.push(&offset);
        }
        
        debug!("ğŸ“Š æ‰§è¡ŒæŸ¥è¯¢: {}", query);
        
        // è¿™é‡Œç”±äºsqlxçš„é™åˆ¶ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æ„å»ºæŸ¥è¯¢
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå»ºè®®ä½¿ç”¨æŸ¥è¯¢æ„å»ºå™¨æˆ–æ›´å®‰å…¨çš„æ–¹æ³•
        let metrics = match param_count {
            0 => sqlx::query_as::<_, AggregatedMetric>(&query)
                .fetch_all(&self.pool)
                .await?,
            1 => sqlx::query_as::<_, AggregatedMetric>(&query)
                .bind(params[0])
                .fetch_all(&self.pool)
                .await?,
            2 => sqlx::query_as::<_, AggregatedMetric>(&query)
                .bind(params[0])
                .bind(params[1])
                .fetch_all(&self.pool)
                .await?,
            _ => {
                // å¯¹äºæ›´å¤æ‚çš„æŸ¥è¯¢ï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´é€šç”¨çš„æ–¹æ³•
                let rows = sqlx::query(&query)
                    .fetch_all(&self.pool)
                    .await?;
                
                rows.into_iter()
                    .map(|row| AggregatedMetric {
                        id: row.get("id"),
                        source: row.get("source"),
                        metric_name: row.get("metric_name"),
                        value: row.get("value"),
                        timestamp: row.get("timestamp"),
                        created_at: row.get("created_at"),
                        updated_at: row.get("updated_at"),
                        metadata: row.get("metadata"),
                    })
                    .collect()
            }
        };
        
        debug!("ğŸ“Š æŸ¥è¯¢è¿”å› {} æ¡è®°å½•", metrics.len());
        
        Ok(metrics)
    }
    
    /// è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    /// 
    /// # è¿”å›
    /// * `Result<MetricStats>` - ç»Ÿè®¡ä¿¡æ¯æˆ–é”™è¯¯
    pub async fn get_stats(&self) -> Result<MetricStats> {
        debug!("ğŸ“ˆ æ­£åœ¨è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯...");
        
        // è·å–æ€»è®°å½•æ•°
        let total_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM aggregated_metrics")
            .fetch_one(&self.pool)
            .await?;
        
        // æŒ‰æ•°æ®æºåˆ†ç»„ç»Ÿè®¡
        let source_stats = sqlx::query("SELECT source, COUNT(*) as count FROM aggregated_metrics GROUP BY source")
            .fetch_all(&self.pool)
            .await?;
        
        let mut by_source = std::collections::HashMap::new();
        for row in source_stats {
            let source: String = row.get("source");
            let count: i64 = row.get("count");
            by_source.insert(source, count);
        }
        
        // æŒ‰æŒ‡æ ‡åç§°åˆ†ç»„ç»Ÿè®¡
        let metric_stats = sqlx::query("SELECT metric_name, COUNT(*) as count FROM aggregated_metrics GROUP BY metric_name")
            .fetch_all(&self.pool)
            .await?;
        
        let mut by_metric = std::collections::HashMap::new();
        for row in metric_stats {
            let metric_name: String = row.get("metric_name");
            let count: i64 = row.get("count");
            by_metric.insert(metric_name, count);
        }
        
        // è·å–æœ€æ–°å’Œæœ€æ—©çš„æ•°æ®æ—¶é—´
        let latest_timestamp: Option<DateTime<Utc>> = sqlx::query_scalar(
            "SELECT MAX(timestamp) FROM aggregated_metrics"
        )
        .fetch_one(&self.pool)
        .await?;
        
        let earliest_timestamp: Option<DateTime<Utc>> = sqlx::query_scalar(
            "SELECT MIN(timestamp) FROM aggregated_metrics"
        )
        .fetch_one(&self.pool)
        .await?;
        
        let stats = MetricStats {
            total_count,
            by_source,
            by_metric,
            latest_timestamp,
            earliest_timestamp,
        };
        
        debug!("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯è·å–å®Œæˆ: {} æ¡è®°å½•", total_count);
        
        Ok(stats)
    }
    
    /// åˆ é™¤è¿‡æœŸæ•°æ®
    /// 
    /// # å‚æ•°
    /// * `before` - åˆ é™¤æ­¤æ—¶é—´ä¹‹å‰çš„æ•°æ®
    /// 
    /// # è¿”å›
    /// * `Result<u64>` - åˆ é™¤çš„è®°å½•æ•°æˆ–é”™è¯¯
    pub async fn delete_old_data(&self, before: DateTime<Utc>) -> Result<u64> {
        info!("ğŸ—‘ï¸  æ­£åœ¨åˆ é™¤ {} ä¹‹å‰çš„æ•°æ®", before);
        
        let result = sqlx::query("DELETE FROM aggregated_metrics WHERE timestamp < $1")
            .bind(before)
            .execute(&self.pool)
            .await
            .context("åˆ é™¤è¿‡æœŸæ•°æ®å¤±è´¥")?;
        
        let deleted_count = result.rows_affected();
        info!("âœ… åˆ é™¤äº† {} æ¡è¿‡æœŸæ•°æ®", deleted_count);
        
        Ok(deleted_count)
    }
    
    /// è·å–æ•°æ®åº“è¿æ¥æ± çš„å¼•ç”¨
    /// 
    /// ç”¨äºéœ€è¦ç›´æ¥è®¿é—®æ•°æ®åº“çš„åœºæ™¯
    pub fn pool(&self) -> &PgPool {
        &self.pool
    }
} 